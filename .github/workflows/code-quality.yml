name: Code Quality

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly code quality analysis
    - cron: '0 8 * * 1'

env:
  PYTHON_VERSION: "3.12"

jobs:
  code-analysis:
    name: Static Code Analysis
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend
        
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis
          
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-quality-${{ hashFiles('backend/requirements.txt') }}
          
      - name: Install dependencies and analysis tools
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install \
            flake8 \
            flake8-bugbear \
            flake8-comprehensions \
            flake8-docstrings \
            flake8-import-order \
            flake8-quotes \
            mypy \
            black \
            isort \
            bandit \
            radon \
            vulture \
            pydocstyle
            
      - name: Run Black code formatting check
        run: |
          black --check --diff .
          
      - name: Run isort import sorting check
        run: |
          isort --check-only --diff .
          
      - name: Run flake8 linting with plugins
        run: |
          flake8 . \
            --max-line-length=120 \
            --max-complexity=10 \
            --select=E,W,F,B,C,I,Q,D \
            --ignore=E203,W503,D100,D101,D102,D103,D104,D105 \
            --exclude=venv,__pycache__,.git,build,dist,*.egg-info \
            --format='%(path)s:%(row)d:%(col)d: %(code)s %(text)s'
            
      - name: Run mypy type checking
        run: |
          mypy main.py --config-file mypy.ini --show-error-codes --pretty
          
      - name: Run pydocstyle documentation check
        run: |
          pydocstyle . --convention=google --add-ignore=D100,D101,D102,D103,D104,D105
          
      - name: Run bandit security linting
        run: |
          bandit -r . -f json -o bandit-report.json || true
          bandit -r . --severity-level medium --confidence-level medium
          
      - name: Analyze code complexity
        run: |
          echo "## Code Complexity Analysis" >> $GITHUB_STEP_SUMMARY
          echo "### Cyclomatic Complexity (CC > 10 functions):" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          radon cc . --show-complexity --min=C --no-assert >> $GITHUB_STEP_SUMMARY || echo "No complex functions found" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          
          echo "### Maintainability Index (MI < B grade):" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          radon mi . --show --min=C >> $GITHUB_STEP_SUMMARY || echo "All files have good maintainability" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          
      - name: Detect dead code
        run: |
          vulture . --min-confidence 80 > vulture-report.txt || true
          if [ -s vulture-report.txt ]; then
            echo "## Dead Code Detection" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            head -20 vulture-report.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload analysis reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: code-analysis-reports
          path: |
            backend/bandit-report.json
            backend/vulture-report.txt
            
  sonarcloud:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    if: github.repository_owner == 'your-org' # Replace with your organization
    defaults:
      run:
        working-directory: backend
        
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Run tests with coverage
        run: |
          pytest --cov=. --cov-report=xml --cov-report=html
          
      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          projectBaseDir: backend/
          
  dependency-review:
    name: Dependency Review
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Dependency Review
        uses: actions/dependency-review-action@v4
        with:
          fail-on-severity: critical
          allow-ghsas: GHSA-xxxx-xxxx-xxxx # Add specific allowlist if needed
          
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    defaults:
      run:
        working-directory: backend
        
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-benchmark
          
      - name: Run performance benchmarks
        run: |
          if [ -d "tests/benchmarks" ]; then
            pytest tests/benchmarks/ --benchmark-json=benchmark-results.json
          else
            echo "No benchmark tests found"
          fi
          
      - name: Store benchmark results
        if: github.ref == 'refs/heads/main'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: backend/benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          
  generate-quality-report:
    name: Generate Quality Report
    runs-on: ubuntu-latest
    needs: [code-analysis]
    if: always()
    
    steps:
      - name: Download analysis reports
        uses: actions/download-artifact@v3
        with:
          name: code-analysis-reports
          path: reports/
          
      - name: Generate quality summary
        run: |
          echo "# 📊 Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Analysis Results" >> $GITHUB_STEP_SUMMARY
          echo "| Tool | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Analysis | ${{ needs.code-analysis.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "reports/bandit-report.json" ]; then
            echo "## Security Issues" >> $GITHUB_STEP_SUMMARY
            SECURITY_ISSUES=$(jq '.results | length' reports/bandit-report.json)
            echo "Found $SECURITY_ISSUES potential security issues" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Generated:** $(date -u)" >> $GITHUB_STEP_SUMMARY